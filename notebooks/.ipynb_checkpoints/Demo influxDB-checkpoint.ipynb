{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7ddaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2906969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_db(db_list, db_name, db_search):\n",
    "    # print(db_name)\n",
    "    runtime_list = []\n",
    "    for db in db_list:\n",
    "        if db_search in db:\n",
    "            with open(workdir + db_dir + \"/\" + db) as csv_file:\n",
    "                csv_reader = list(csv.reader(csv_file, delimiter=','))[1:]\n",
    "                for row in csv_reader:\n",
    "                    # print(\"\\t\", row[-2], row[-1])\n",
    "                    dict_0 = json.loads(row[3])\n",
    "                    event_time = dict_0[\"Records\"][0][\"eventTime\"]\n",
    "                    dt = dateutil.parser.isoparse(event_time)\n",
    "                    event_time = dt.timestamp()\n",
    "                    runtime = round(float(row[-1]) - float(event_time), 3)\n",
    "                    # print(\"\\t\", str(runtime))\n",
    "                    runtime_list.append(runtime)\n",
    "    return runtime_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c8026",
   "metadata": {},
   "source": [
    "## Runtime check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a24517d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "workdir = \"/home/scrapjack/PycharmProjects/OSCAR-P/runs-results/annotations-test/Database/\"\n",
    "\n",
    "database_dirs = sorted(os.listdir(workdir))\n",
    "database_dirs.remove(\"output\")\n",
    "\n",
    "csv_header = \"blur_1, blur_2, mask_1, mask_2, dummy_1, dummy_2, total\"\n",
    "csv_content = []\n",
    "\n",
    "for db_dir in database_dirs:\n",
    "    # print(db_dir)\n",
    "    \n",
    "    db_list = sorted(os.listdir(workdir + db_dir))\n",
    "    # print(db_list)\n",
    "    \n",
    "    blurs = get_right_db(db_list, \"blurry-faces\", \"blur\")\n",
    "    masks = get_right_db(db_list, \"mask-detector\", \"mask\")\n",
    "    dummies = get_right_db(db_list, \"dummy\", \"dummy\")\n",
    "    \n",
    "    times = blurs + masks + dummies\n",
    "    \n",
    "    total = 0\n",
    "    for t in times:\n",
    "        total += t\n",
    "    \n",
    "    times += [round(total, 3)]\n",
    "    \n",
    "    csv_content.append(str(times))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe915e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/summary.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_content:\n",
    "        file.write(row[1:-1] + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c29a5e",
   "metadata": {},
   "source": [
    "## Constraints check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a559c868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "workdir = \"/home/scrapjack/PycharmProjects/OSCAR-P/runs-results/annotations-test/Database/\"\n",
    "\n",
    "database_dirs = sorted(os.listdir(workdir))\n",
    "database_dirs.remove(\"output\")\n",
    "\n",
    "csv_header = \"blur, mask, dummy, blur+mask, mask+dummy, global\"\n",
    "csv_content = []\n",
    "\n",
    "for db_dir in database_dirs:\n",
    "    # print(db_dir)\n",
    "    \n",
    "    db_list = sorted(os.listdir(workdir + db_dir))\n",
    "    # print(db_list)\n",
    "    \n",
    "    blurs = get_right_db(db_list, \"blurry-faces\", \"blur\")\n",
    "    blur = blurs[0] + blurs[1]\n",
    "    masks = get_right_db(db_list, \"mask-detector\", \"mask\")\n",
    "    mask = masks[0] + masks[1]\n",
    "    dummies = get_right_db(db_list, \"dummy\", \"dummy\")\n",
    "    dummy = dummies[0] + dummies[1]\n",
    "    \n",
    "    blur_mask = blur + mask\n",
    "    mask_dummy = mask + dummy\n",
    "    global_time = blur + mask + dummy\n",
    "    \n",
    "    times = [blur, mask, dummy, blur_mask, mask_dummy, global_time]\n",
    "    \n",
    "    for i in range(len(times)):\n",
    "        times[i] = round(times[i], 3)\n",
    "    \n",
    "    csv_content.append(str(times))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c358af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/constraints_check.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_content:\n",
    "        file.write(row[1:-1] + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba77945",
   "metadata": {},
   "source": [
    "## Constraints validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0894c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "workdir = \"/home/scrapjack/PycharmProjects/OSCAR-P/runs-results/annotations-test/Database/\"\n",
    "\n",
    "database_dirs = sorted(os.listdir(workdir))\n",
    "database_dirs.remove(\"output\")\n",
    "\n",
    "csv_header = \"blur, mask, dummy, blur+mask, mask+dummy, global\"\n",
    "csv_content = []\n",
    "\n",
    "for db_dir in database_dirs:\n",
    "    # print(db_dir)\n",
    "    \n",
    "    db_list = sorted(os.listdir(workdir + db_dir))\n",
    "    # print(db_list)\n",
    "    \n",
    "    blurs = get_right_db(db_list, \"blurry-faces\", \"blur\")\n",
    "    blur = blurs[0] + blurs[1]\n",
    "    masks = get_right_db(db_list, \"mask-detector\", \"mask\")\n",
    "    mask = masks[0] + masks[1]\n",
    "    dummies = get_right_db(db_list, \"dummy\", \"dummy\")\n",
    "    dummy = dummies[0] + dummies[1]\n",
    "    \n",
    "    blur_mask = blur + mask\n",
    "    mask_dummy = mask + dummy\n",
    "    global_time = blur + mask + dummy\n",
    "    \n",
    "    checks = [0] * 6\n",
    "    times = [blur, mask, dummy, blur_mask, mask_dummy, global_time]\n",
    "    constraints = [5, 5, 20, 10, 20, 20]\n",
    "    \n",
    "    for i in range(6):\n",
    "        if times[i] > constraints[i]:\n",
    "            checks[i] = 1\n",
    "    \n",
    "    csv_content.append(str(checks))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1d56140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/constraints_validation.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_content:\n",
    "        file.write(row[1:-1] + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca8415",
   "metadata": {},
   "source": [
    "## Merge influxdb.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "068550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_row(row, db_search, i):\n",
    "    dict_0 = json.loads(row[3])\n",
    "    event_time = dict_0[\"Records\"][0][\"eventTime\"]\n",
    "    \n",
    "    dt = dateutil.parser.isoparse(event_time)\n",
    "    event_time = dt.timestamp()\n",
    "    \n",
    "    row[3] = str(event_time)\n",
    "    row[0] = \"video_\" + str(i)\n",
    "    row[2] = db_search\n",
    "    \n",
    "    #print(row)\n",
    "    \n",
    "    row_string = ','.join([elem for elem in row])\n",
    "    # print(row_string)\n",
    "    \n",
    "    return row_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1975cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_content(db_list, db_search, i):\n",
    "    lines = []\n",
    "    for db in db_list:\n",
    "        if db_search in db:\n",
    "            with open(workdir + db_dir + \"/\" + db) as csv_file:\n",
    "                # lines += csv_file.readlines()[1:]\n",
    "                csv_rows = list(csv.reader(csv_file, delimiter=','))[1:]\n",
    "                for row in csv_rows:\n",
    "                    lines += [correct_row(row, db_search, i)]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0c849d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "workdir = \"/home/scrapjack/PycharmProjects/OSCAR-P/runs-results/annotations-test/Database/\"\n",
    "\n",
    "database_dirs = sorted(os.listdir(workdir))\n",
    "database_dirs.remove(\"output\")\n",
    "\n",
    "csv_header = \"uuid,resource_id,component_name,start_time_job,start_time_func,end_time_func\"\n",
    "csv_content = []\n",
    "\n",
    "for i in range(len(database_dirs)):\n",
    "    db_dir = database_dirs[i]\n",
    "    # print(db_dir)\n",
    "    \n",
    "    db_list = sorted(os.listdir(workdir + db_dir))\n",
    "    # print(db_list)\n",
    "    \n",
    "    blurs = get_csv_content(db_list, \"blur\", i)\n",
    "    masks = get_csv_content(db_list, \"mask\", i)\n",
    "    dummies = get_csv_content(db_list, \"dummy\", i)\n",
    "    \n",
    "    lines = blurs + masks + dummies\n",
    "    # print(len(lines))\n",
    "    \n",
    "    csv_content += lines\n",
    "\n",
    "# print(len(csv_content))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2498bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/influxdb.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_content:\n",
    "        file.write(row + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5ea91",
   "metadata": {},
   "source": [
    "## Parse influxdb.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cc0bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first(values):\n",
    "    first = values[0]\n",
    "    for v in values:\n",
    "        if v < first:\n",
    "            first = v\n",
    "    \n",
    "    return first\n",
    "    \n",
    "    \n",
    "def get_last(values):\n",
    "    last = values[0]\n",
    "    for v in values:\n",
    "        if v > last:\n",
    "            last = v\n",
    "    \n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8de6125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(rows, index):\n",
    "    values = []\n",
    "    for r in rows:\n",
    "        values.append(r[index])\n",
    "    \n",
    "    return values\n",
    "    \n",
    "\n",
    "def get_interval_runtime(rows):\n",
    "    values = get_values(rows, 3)\n",
    "    first = get_first(values)\n",
    "    values = get_values(rows, 5)\n",
    "    last = get_last(values)\n",
    "    runtime = round(float(last) - float(first), 3)\n",
    "    \n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8241e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(workdir + \"output/influxdb.csv\", \"r\") as influxdb_csv:\n",
    "    influxdb_content = list(csv.reader(influxdb_csv, delimiter=','))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e5e3379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csv_header = \"blur, mask, dummy, blur+mask, mask+dummy, global\"\n",
    "csv_content = []\n",
    "csv_checks = []\n",
    "\n",
    "for i in range(15):\n",
    "    blur_1 = influxdb_content[i*6]\n",
    "    blur_2 = influxdb_content[i*6 + 1]\n",
    "    mask_1 = influxdb_content[i*6 + 2]\n",
    "    mask_2 = influxdb_content[i*6 + 3]\n",
    "    dummy_1 = influxdb_content[i*6 + 4]\n",
    "    dummy_2 = influxdb_content[i*6 + 5]\n",
    "    \n",
    "    blur = get_interval_runtime([blur_1, blur_2])\n",
    "    mask = get_interval_runtime([mask_1, mask_2])\n",
    "    dummy = get_interval_runtime([dummy_1, dummy_2])\n",
    "    \n",
    "    blur_mask = get_interval_runtime([blur_1, blur_2, mask_1, mask_2])\n",
    "    mask_dummy = get_interval_runtime([mask_1, mask_2, dummy_1, dummy_2])\n",
    "    global_time = get_interval_runtime([blur_1, blur_2, mask_1, mask_2, dummy_1, dummy_2])\n",
    "    \n",
    "    times = [blur, mask, dummy, blur_mask, mask_dummy, global_time]\n",
    "    \n",
    "    for i in range(len(times)):\n",
    "        times[i] = round(times[i], 3)\n",
    "    \n",
    "    checks = [0] * 6\n",
    "    constraints = [30, 30, 30, 50, 50, 60]\n",
    "    \n",
    "    for i in range(6):\n",
    "        if times[i] > constraints[i]:\n",
    "            checks[i] = 1\n",
    "    \n",
    "    csv_checks.append(str(checks))    \n",
    "    csv_content.append(str(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05979d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video_0', 'vnode-2.localdomain', 'blur', '1655131211.386', '1655131226.1276991', '1655131228.3781693']\n",
      "['video_0', 'vnode-2.localdomain', 'blur', '1655131211.386', '1655131232.2079945', '1655131234.4072266']\n",
      "['video_0', 'vnode-2.localdomain', 'mask', '1655131235.367', '1655131244.2007', '1655131244.616981']\n",
      "['video_0', 'vnode-2.localdomain', 'mask', '1655131235.398', '1655131253.8901649', '1655131254.3599198']\n",
      "['video_0', 'vnode-2.localdomain', 'dummy', '1655131244.774', '1655131263.0724108', '1655131273.6605575']\n",
      "['video_0', 'vnode-2.localdomain', 'dummy', '1655131254.549', '1655131281.968743', '1655131295.6933305']\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    blur_1 = influxdb_content[i*6]\n",
    "    blur_2 = influxdb_content[i*6 + 1]\n",
    "    mask_1 = influxdb_content[i*6 + 2]\n",
    "    mask_2 = influxdb_content[i*6 + 3]\n",
    "    dummy_1 = influxdb_content[i*6 + 4]\n",
    "    dummy_2 = influxdb_content[i*6 + 5]\n",
    "    \n",
    "    print(blur_1)\n",
    "    print(blur_2)\n",
    "    print(mask_1)\n",
    "    print(mask_2)\n",
    "    print(dummy_1)\n",
    "    print(dummy_2)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5edfb55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/constraints_validation.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_content:\n",
    "        file.write(row[1:-1] + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "161f7d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(workdir + \"output/constraints_check.csv\", \"w\") as file:\n",
    "    file.write(csv_header + \"\\n\")\n",
    "    for row in csv_checks:\n",
    "        file.write(row[1:-1] + \"\\n\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
